I'm now going to g*** you two m*** example problems of computing. eigendecomposition of matrices by hand. Obviously t*** is on the computer but I encourage you to do these problems by h*** and they're not d*** in Matlab. So I guess that's w*** it means by hand. So let's get started. H*** is a two by two matrix and you should pause the video go through f*** the eigenvalues and the eigenvectors of t*** matrix so the way we start is by shifting the matrix by Lambda so subtracting lambda f*** the diagonal elements setting the determinant equal to z*** and t*** proceeding to compute the determinant which is a*** called the characteristic equation of t*** matrix. So t*** works out to be three minus lambda times six minus lambda minus f*** equals z*** and t*** expanding these two terms multiplying out these two terms and t*** collecting the l*** terms gives us lambda squared minus n*** lambda p*** fourteen equals z*** and t*** t*** expression h*** can be factored i*** lambda minus seven and Lambda minus two and now it's pretty e*** to see t*** the two lambdas t*** w*** solve t*** equation t*** solve t*** equation. In other words the two eigenvalues of t*** matrix are p*** 7 and p*** two. So t*** was s*** one we found the eigenvalues of t*** matrix and now we go through for e*** of these eigenvalues shift the matrix by t*** amount by t*** value and t*** figure out w*** is a vector in the shifted matrices n*** space. OK so let's start w*** 2. So t*** gives us the matrix 1 1 4 4. And now we w*** to f*** the missing vector h*** and you've probably guessed it already it is 1 minus 1. And of course you k*** t*** a*** acceptable would be minus 1 1 or minus quadrillion p*** quadrillion. T*** vector simply identifies a subspace for the n*** space of t*** shifted matrix in any vector that's in t*** n*** space is perfectly f*** as an eigenvector. Now t*** s*** the b*** choice for an eigenvector would be a vector t*** has a n*** of 1 a magnitude of 1. And the second b*** choice would be integer values t*** are e*** to interpret and compact to write l*** this. All right. So t*** was for two. Now we go to the second eigenvalues which was seven and t*** gives us t*** matrix minus 4 1 and 4 minus 1. And h*** a vector t*** could w*** as an eigenvector as a basis for the n*** space of t*** shifted matrix is the numbers 1 4. So h*** is the big picture overview we h*** t*** matrix and h*** you see the eigenvalue and its corresponding eigenvector and the other eigenvalue and the other corresponding eigenvector. Now y*** results w*** be correct. If you h*** the correct pairing of eigenvalue and any multiple any scaled version of t*** vector; it doesn't matter if you c*** t*** lambda one and t*** V one that's f*** because there's no intrinsic ordering. W*** matters is t*** you h*** the pairing correct. All right. So t*** was the two by two case. Now let's go for a three by three case. T*** one is a little bit m*** challenging and I h*** to admit. So I first c*** up w*** these numbers and t*** I started computing the eigendecomposition. Now I h*** to admit t*** I got stuck on one of the eigenvectors. I couldn't quite figure it out on my own. So I u*** Matlab to compute t*** eigenvector. So w*** I encourage you to do is f*** all three eigenvalues by h*** and I think it w*** be pretty obvious w*** you start working through it which is the difficult eigenvalue. So t*** w*** you should do by h*** is f*** two of the eigenvectors t*** you can get basically j*** by k*** of eyeballing and making s*** educated guesses. And t*** the third eigenvector you can use a computer to solve or you can j*** w*** and watch me c*** up w*** a solution. All right. So again we start by shifting t*** matrix by minus lambda setting the determinant equal to z*** and t*** proceeding to compute the determinant of t*** equation and altogether t*** gives us the characteristic equation of t*** matrix. Now t*** is a little bit longer. It's a little bit trickier the arithmetic g*** a little bit hairy in particular you end up w*** t*** minus lambda cubed t*** as w*** as a couple of multiple terms w*** Lambda and Lambda squared. Now o*** you collect all of these l*** terms you'll end up w*** an expression t*** looks l*** this. So it should be minus lambda cubed p*** 10 times lambda squared p*** eleven lambda equals z*** Now something interesting has happened h*** all of these terms h*** a lambda attached to t*** which means t*** we can t*** a lambda out of e*** of these terms and rewrite t*** expression as minus lambda times. All of t*** stuff and immediately t*** tells us t*** lambda equals z*** is a solution. So w*** you set t*** lambda to be z*** it doesn't actually matter what's inside t*** parenthetical statement that's immediately going to set to m*** t*** equation true. T*** means t*** one of the eigenvalues of t*** matrix is z*** and I'm going to h*** an entire video j*** about t*** phenomenon a little bit later in t*** section. But essentially w*** an eigenvector is an eigenvalue is zero. It means t*** the matrix is singular and t*** you can actually see by looking at t*** matrix and you see t*** column 1 p*** column 2 equals column 3 so whenever you h*** a singular matrix at least one eigenvalues value is going to be equal to zero. And in f*** the number of eigenvalues t*** are equal to z*** tells you about the r*** of t*** matrix. M*** on t*** in the later video. Now o*** you've gotten to t*** s*** you can further factor t*** equation and you end up w*** the result t*** lambda equals z*** lambda equals minus 1 and Lambda equals eleven. So you can probably guess t*** t*** is going to be the tricky I can value to compute the corresponding I can vector of and t*** is the one t*** I got a little bit stuck with. And so I u*** Matlab as a crutch. I cheated a little bit. OK so but let's go through all of these. So we start w*** z*** and now t*** is k*** of a funny thing because we are shifting the matrix by z*** which actually means we're not changing the matrix at all. And t*** means t*** t*** matrix A already has a non-trivial n*** space e*** without doing any shifting. So t*** problem actually boils d*** to finding a vector in the n*** space or a basis for the n*** space. E*** without doing any shifting so based on w*** I j*** t*** you about how do I set up t*** matrix t*** column one p*** column two equals column three a basis for the n*** space is 1 one minus 1. So you can try for e*** of these r*** the first column p*** the second column minus the third column equals z*** all right. So now let's m*** on. So now we shift t*** matrix by eleven and t*** is basically where I got stuck and switch to matlab. So it turns out t*** eigenvector is nineteen forty one and thirty six. So if you figured out t*** I can vector on y*** own without using a computer t*** g*** for you you are a better or at least m*** patient mathematician t*** I am. And t*** we get to the third eigenvalue which was minus one. So now t*** becomes p*** one. And h*** is t*** shifted matrix and t*** one you should be a*** to solve on y*** own. In f*** it's e*** easier t*** it looks. And if you n*** a h*** before I s*** the answer t*** the h*** is j*** consider t*** t*** third column is actually pretty useless if you get rid of t*** third column it becomes really e*** to f*** the eigenvector in t*** shifted matrices n*** space. So in f*** it's one minus one and t*** z*** you j*** set the third element to be zero. So t*** leads us to the big picture overview of the eigendecomposition of t*** three by three singular matrix r*** 2 matrix we h*** eigenvalues 0 minus 11 and minus 1. And these are the corresponding eigenvectors. And notice I*** written t*** as row vectors and t*** transpose. So these are still column vectors we generally always think about eigenvectors as column vectors and you w*** learn m*** about why t*** is the c*** in the video on diagonalization, which is coming up soon.